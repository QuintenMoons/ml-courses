{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "63445178",
            "metadata": {},
            "source": [
                "# Evaluatie\n",
                "(target-evaluation)=\n",
                "Wanneer een machine learning model getraind wordt, is het cruciaal om de uiteindelijke **model-performantie** na te gaan. Dat houdt specifiek de vraag in **of het model er al dan niet in slaagt om bruikbare taak-outputs te genereren bij nieuwe data**. Dit is het domein van **modelevaluatie**. Bij die evaluatie worden **de prestaties van een model geëvalueerd op basis van performantiematen; beter bekend als _scoring metrics_**.  \n",
                "  \n",
                "Als er een _loss_ functie gebruikt wordt tijdens het trainen, geeft de waarde daarvan een eerste indicatie van de model-performantie. De _loss_ functie geeft echter niet noodzakelijk rechtstreeks een zicht op taakprestaties. Daarom worden tal van andere _ scoring metrics_ gebruikt, afhankelijk van de specifieke taak.  \n",
                "  \n",
                "We zullen zien dat er verschillende _metrics_ gangbaar zijn, afhankelijk van de taakcontext (bv. klassificatie, regressie, enz.) en het specifieke domein (bv. computervisie, NLP, enz.; zie [_scikit-learn metrics_ module](https://scikit-learn.org/stable/api/sklearn.metrics.html#module-sklearn.metrics) en [_scikit-learn scoring guide_](https://scikit-learn.org/stable/modules/model_evaluation.html#metrics-and-scoring-quantifying-the-quality-of-predictions)).  \n",
                "\n",
                ":::{note} _Precision_ & _Recall_\n",
                ":class: dropdown\n",
                "(target-accuracy)=\n",
                "In de context van klassificatie, kijken we in de eerste plaats naar de _accuracy_ score; het percentage juist voorspelde categorieën.  \n",
                "In onderstaande _confusion matrix_ is de _accuracy_ $100 \\times \\frac{45+38+35}{45+3+2+2+38+1+1+4+35}$\n",
                "```\n",
                "                 Voorspeld\n",
                "               Kat  Hond  Vogel\n",
                "Werkelijk Kat   45    3     2\n",
                "          Hond   2   38     1\n",
                "          Vogel  1    4    35\n",
                "```\n",
                "  \n",
                "Daarnaast wordt bij _binaire_ klassificatie (bv. Kat|hond) ook gekeken naar de verdeling van het aantal _true positives_ (TP), _false positives_ (FP), _true negatives_ (TN) en _false negatives_ (FN).\n",
                "\n",
                "```\n",
                "                   Voorspeld\n",
                "                 Kat(+)  Hond(-)\n",
                "Werkelijk Kat(+)   45        3\n",
                "          Hond(-)   2       38\n",
                "```\n",
                "\n",
                "$TP = \\frac{45}{47}$,\n",
                "$FP = \\frac{2}{47}$,\n",
                "$TN = \\frac{38}{41}$ en\n",
                "$FN = \\frac{3}{41}$\n",
                "  \n",
                "Hieraan worden drie metrics gekoppeld:  \n",
                "(target-precision)=\n",
                "1. _Precision_: Fractie van positieve voorspellingen die correct zijn\n",
                "\n",
                "$$\n",
                "Precision = \\frac{TP}{TP + FP}\n",
                "$$\n",
                "(target-recall)=  \n",
                "2. _Recall_: Fractie van positieve instances die correct geïdentificeerd zijn\n",
                "\n",
                "$$\n",
                "Recall = \\frac{TP}{TP + FN}\n",
                "$$\n",
                "\n",
                "(target-F-score)=\n",
                "3. _$F_1$-score_: Harmonisch gemiddelde van _precision_ en _recall_. De score groeit symmetrisch met toenemende _precision_ of _recall_.\n",
                "$$\n",
                "F_1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}\n",
                "$$\n",
                "Een algemenere maat is de $F_{\\beta}-score$ waarbij een gewicht wordt toegekend om _precision_ meer of minder belang te geven ten opzichte van _recall_.\n",
                "  \n",
                "[![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png)](https://en.wikipedia.org/wiki/F-score)\n",
                ":::\n",
                "  \n",
                "\n",
                "(target-validation)=\n",
                "## Training, validatie en testing\n",
                "Om zeker te zijn dat een model patronen leert te herkennen en niet gewoon de trainingsdata van buiten leert, is het cruciaal om de prestaties te evalueren op ongeziene data. **De capaciteit om juiste voorspellingen te maken met _nieuwe data_ wordt algemeen de _generalisatie_ capaciteit van het model genoemd**. Er wordt in die context standaard een onderscheid gemaakt tussen drie groepen data:  \n",
                "1. **Trainingsdata**: dit is de bulk van de data (bv. 70%) waarmee we ons leeralgoritme effectief laten werken om de optimale modelparameters te vinden.\n",
                "2. **Validatiedata**: dit is een kleiner stuk van de data (bv.20%) waarmee we _tijdens de training en hyper parameter tuning_ evalueren hoe het model presteert op ongeziene data.\n",
                "3. **Testdata**: dit is een (meestal nog) kleiner stuk van de data (bv. 10%) dat volledig opzij gehouden wordt. Het model kan nooit (rechtstreeks of onrechtstreeks) beïnvloed worden door deze data tijdens de training. Ze dienen om de **generalisatie** capaciteit van het model finaal te kwantificeren.  \n",
                "  \n",
                "Vaak wordt met een meer geavanceerde vorm van validatie gewerkt: zogenaamde _K-Fold Cross_-validatie. In plaats van één stuk data opzij te houden als validatie data, wordt de trainingsdata in _K_ gelijke delen op gesplitst. Het model wordt dan bij iedere tussenstap _K_ keer getraind met _K-1_ delen en gevalideerd met het overige deel.  \n",
                "  \n",
                "[![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png?raw=true)](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
                "\n",
                "## _Explainability_\n",
                "(target-explainability)=\n",
                "Bij de evaluatie van modellen is het zaak om ook inzicht te krijgen in de effectieve patronen die geleerd zijn en **hoe een model, gegeven concrete inputs, tot bepaalde voorspellingen komt**. Dit is bij bepaalde toepassingen (bv. medische diagnostiek) cruciaal. Zoals we zullen zien in de secties over concrete toepassingsdomeinen, is dit, afhankelijk van het type model, niet altijd even evident.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ml-courses",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
