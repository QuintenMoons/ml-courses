{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3bDMYHj5XFV"
      },
      "source": [
        "[![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=grey&color=yellow&logoColor=white&label=%20&style=flat-square)](https://colab.research.google.com/github/ap-mdi-it/ml-courses/blob/main/book/ml_principles/labo/taco.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8USnnIv_5XFZ"
      },
      "source": [
        "Navigeer naar deze notebook op GitHub: [https://github.com/ap-mdi-it/ml-courses/blob/main/book/ml_principles/labo/taco.ipynb](https://github.com/ap-mdi-it/ml-courses/blob/main/book/ml_principles/labo/taco.ipynb)  \n",
        "  \n",
        "Via bovenstaande link kan je deze notebook openen in Google Colaboratory. In die omgeving kunnen we gebruik maken van gratis quota voor GPUs (en TPUs). GPU acceleratie is hier sterk aanbevolen voor zowel model training als model inference.  \n",
        "  \n",
        "Deze notebook is gebaseerd op: [https://www.kaggle.com/code/shuvosharkr/taco-trash-detection-yolov8s](https://www.kaggle.com/code/shuvosharkr/taco-trash-detection-yolov8s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8SMvDcy5XFc"
      },
      "source": [
        "# Colab setup\n",
        "- Als je de notebook voor het eerst opent op Colab, kies je in het menu rechts bovenaan `Connect > Change runtime type`: `Python 3` en `T4 GPU`.\n",
        "- Pas nadat de GPU Runtime is opgestart ga je verder met onderstaande installatie van het [ultralitics](https://github.com/ultralytics/ultralytics) package.\n",
        "- ⚠️ Bij deze waarschuwing `Warning: This notebook was not authored by Google` selecteer je `Run anyway`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KNyKnjrP5XFe",
        "outputId": "9991ea6c-b739-4d81-e21f-f472c7705869"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-11T15:36:34.508841Z",
          "iopub.status.busy": "2025-04-11T15:36:34.508595Z",
          "iopub.status.idle": "2025-04-11T15:36:34.513155Z",
          "shell.execute_reply": "2025-04-11T15:36:34.512188Z",
          "shell.execute_reply.started": "2025-04-11T15:36:34.508822Z"
        },
        "id": "FB215svG5XFg",
        "outputId": "223e7bea-4d7d-4e85-afa7-046c6338a595",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from pprint import pprint\n",
        "\n",
        "import kagglehub\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import yaml\n",
        "from PIL import Image, ImageDraw\n",
        "from ultralytics import YOLO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsiCbf-35XFi"
      },
      "outputs": [],
      "source": [
        "# Set Colab datasets directory for Ultralytics package\n",
        "with open(\"/root/.config/Ultralytics/settings.json\") as f:\n",
        "    settings = json.load(f)\n",
        "    settings[\"datasets_dir\"] = \"/contents\"\n",
        "\n",
        "with open(\"/root/.config/Ultralytics/settings.json\", \"w\") as f:\n",
        "    json.dump(settings, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZPe85lj5XFk"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qzVWhYv5XFl",
        "outputId": "a1a66a69-77da-4846-8626-26f41015f417"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"vencerlanz09/taco-dataset-yolo-format\")\n",
        "\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyac6AYD5XFm",
        "outputId": "a87b4ac4-6e8f-4993-fd6a-637f797ca32c"
      },
      "outputs": [],
      "source": [
        "# Copy the contents of the directory instead of moving it to avoid permission issues\n",
        "destination = \"./taco\"\n",
        "if not os.path.exists(destination):\n",
        "    shutil.copytree(path, destination)\n",
        "path = destination\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqFo6pFx-KMz",
        "outputId": "5501086b-1432-4a05-d2b3-f590403ac773"
      },
      "outputs": [],
      "source": [
        "# Update the meta data (see taco#1.ipynb)\n",
        "with open(path + \"/data.yaml\") as f:\n",
        "    meta = yaml.safe_load(f)\n",
        "\n",
        "# Update image paths\n",
        "meta[\"train\"] = path + \"/train/images\"\n",
        "meta[\"val\"] = path + \"/valid/images\"\n",
        "meta[\"test\"] = path + \"/test/images\"\n",
        "\n",
        "# Swap Bottle cap and Bottle labels (see)\n",
        "bottle_cap_idx = meta[\"names\"].index(\"Bottle cap\")\n",
        "bottle_idx = meta[\"names\"].index(\"Bottle\")\n",
        "meta[\"names\"][bottle_cap_idx], meta[\"names\"][bottle_idx] = (\n",
        "    meta[\"names\"][bottle_idx],\n",
        "    meta[\"names\"][bottle_cap_idx],\n",
        ")\n",
        "\n",
        "# write back to file\n",
        "with open(path + \"/data.yaml\", \"w\") as f:\n",
        "    yaml.dump(meta, f)\n",
        "\n",
        "pprint(meta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1UOwrAU5XFv"
      },
      "source": [
        "# Training (hyper) Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-11T15:37:40.353951Z",
          "iopub.status.busy": "2025-04-11T15:37:40.353719Z",
          "iopub.status.idle": "2025-04-11T15:37:40.357679Z",
          "shell.execute_reply": "2025-04-11T15:37:40.356849Z",
          "shell.execute_reply.started": "2025-04-11T15:37:40.353932Z"
        },
        "id": "g7Ar6SUr5XFw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define training parameters\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "imgsz = 640  # Image size\n",
        "optimizer_type = \"AdamW\"  # AdamW optimizer (recommended for better regularization)\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su5f_ST45XFx"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-11T15:37:40.358856Z",
          "iopub.status.busy": "2025-04-11T15:37:40.358529Z"
        },
        "id": "mgtR1YeP5XFx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize YOLOv11 model (pre-trained weights)\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "save_dir = \"./runs/train/exp\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Train model with Cosine Annealing learning rate scheduler\n",
        "model.train(\n",
        "    data=path + \"/data.yaml\",\n",
        "    epochs=epochs,\n",
        "    batch=batch_size,\n",
        "    imgsz=imgsz,\n",
        "    optimizer=optimizer_type,\n",
        "    lr0=lr,  # Initial learning rate\n",
        "    weight_decay=weight_decay,\n",
        "    save=True,  # Save the best model\n",
        "    save_period=1,  # Save model every 10 epochs\n",
        "    val=True,  # Evaluate on validation set\n",
        "    save_dir=save_dir,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOKukj0S5XFy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "best_model = YOLO(\"./runs/detect/train/weights/best.pt\")\n",
        "val_results = best_model.val()\n",
        "\n",
        "print(\"Best Validation Metrics from Best Model:\")\n",
        "print(f\"Precision: {val_results.box.mp:.4f}\")\n",
        "print(f\"Recall: {val_results.box.mr:.4f}\")\n",
        "print(f\"mAP@50: {val_results.box.map50:.4f}\")\n",
        "print(f\"mAP@50-95: {val_results.box.map:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yLp5Vop5XFz"
      },
      "source": [
        "# log file testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnOkbpPX5XF0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Read the log file into a DataFrame\n",
        "log_file = \"./runs/detect/train/results.csv\"\n",
        "log_data = pd.read_csv(log_file)\n",
        "\n",
        "# Check the first few rows of the data and column names\n",
        "print(log_data.columns)\n",
        "print(log_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtbCH9DZ5XF0"
      },
      "source": [
        "# Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_BrXMYQ5XF1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Convert necessary columns to numeric\n",
        "log_data[\"epoch\"] = pd.to_numeric(log_data[\"epoch\"], errors=\"coerce\").astype(\n",
        "    int\n",
        ")  # Convert to integer\n",
        "log_data[\"train/box_loss\"] = pd.to_numeric(log_data[\"train/box_loss\"], errors=\"coerce\")\n",
        "log_data[\"train/cls_loss\"] = pd.to_numeric(log_data[\"train/cls_loss\"], errors=\"coerce\")\n",
        "log_data[\"train/dfl_loss\"] = pd.to_numeric(log_data[\"train/dfl_loss\"], errors=\"coerce\")\n",
        "log_data[\"val/box_loss\"] = pd.to_numeric(log_data[\"val/box_loss\"], errors=\"coerce\")\n",
        "log_data[\"val/cls_loss\"] = pd.to_numeric(log_data[\"val/cls_loss\"], errors=\"coerce\")\n",
        "log_data[\"val/dfl_loss\"] = pd.to_numeric(log_data[\"val/dfl_loss\"], errors=\"coerce\")\n",
        "\n",
        "# Drop rows with NaN values in relevant columns\n",
        "log_data = log_data.dropna(\n",
        "    subset=[\n",
        "        \"epoch\",\n",
        "        \"train/box_loss\",\n",
        "        \"train/cls_loss\",\n",
        "        \"train/dfl_loss\",\n",
        "        \"val/box_loss\",\n",
        "        \"val/cls_loss\",\n",
        "        \"val/dfl_loss\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Plot the training and validation losses\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot training losses\n",
        "plt.plot(\n",
        "    log_data[\"epoch\"], log_data[\"train/box_loss\"], label=\"Train Box Loss\", linestyle=\"-\", marker=\"o\"\n",
        ")\n",
        "plt.plot(\n",
        "    log_data[\"epoch\"],\n",
        "    log_data[\"train/cls_loss\"],\n",
        "    label=\"Train Class Loss\",\n",
        "    linestyle=\"-\",\n",
        "    marker=\"x\",\n",
        ")\n",
        "plt.plot(\n",
        "    log_data[\"epoch\"], log_data[\"train/dfl_loss\"], label=\"Train DFL Loss\", linestyle=\"-\", marker=\"s\"\n",
        ")\n",
        "\n",
        "# Plot validation losses\n",
        "plt.plot(\n",
        "    log_data[\"epoch\"], log_data[\"val/box_loss\"], label=\"Val Box Loss\", linestyle=\"--\", marker=\"o\"\n",
        ")\n",
        "plt.plot(\n",
        "    log_data[\"epoch\"], log_data[\"val/cls_loss\"], label=\"Val Class Loss\", linestyle=\"--\", marker=\"x\"\n",
        ")\n",
        "plt.plot(\n",
        "    log_data[\"epoch\"], log_data[\"val/dfl_loss\"], label=\"Val DFL Loss\", linestyle=\"--\", marker=\"s\"\n",
        ")\n",
        "\n",
        "# Customize the plot\n",
        "plt.title(\"Training and Validation Losses over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks(log_data[\"epoch\"])  # Ensure that the epoch ticks are shown as integers\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h5qFQlO5XF1"
      },
      "source": [
        "# Validation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCnOPFfY5XF2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "results = model.val()  # Evaluate on the validation set\n",
        "print(f\"Validation Results: {results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_wkBAGE5XF3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"Validation Results:\")\n",
        "print(\"Mean Precision:\", results.box.mp)  # Mean Precision\n",
        "print(\"Mean Recall:\", results.box.mr)  # Mean Recall\n",
        "print(\"mAP 50:\", results.box.map50)  # Mean Average Precision at IoU 0.5\n",
        "print(\"mAP 50-95:\", results.box.map)  # Mean Average Precision at IoU 0.5-0.95\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTadpSy65XF3"
      },
      "source": [
        "# Validation Metrics plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa2PJOaa5XF3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Scalar values from results_dict\n",
        "precision = results.results_dict[\"metrics/precision(B)\"]\n",
        "recall = results.results_dict[\"metrics/recall(B)\"]\n",
        "map50 = results.results_dict[\"metrics/mAP50(B)\"]\n",
        "map50_95 = results.results_dict[\"metrics/mAP50-95(B)\"]\n",
        "\n",
        "# Plotting single values (snapshot)\n",
        "metrics = [\"Precision\", \"Recall\", \"mAP50\", \"mAP50-95\"]\n",
        "values = [precision, recall, map50, map50_95]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(metrics, values, color=[\"b\", \"r\", \"g\", \"purple\"])\n",
        "plt.title(\"Model Evaluation Metrics\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC_1c4Yw5XF4"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_MviaZz5XF4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "best_model = YOLO(\"./runs/detect/train/weights/best.pt\")\n",
        "test_results = best_model.val(data=\"data.yaml\", split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFSdkV0G5XF5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Print test metrics\n",
        "print(f\"Test Precision: {test_results.box.mp:.4f}\")\n",
        "print(f\"Test Recall: {test_results.box.mr:.4f}\")\n",
        "print(f\"Test mAP@50: {test_results.box.map50:.4f}\")\n",
        "print(f\"Test mAP@50-95: {test_results.box.map:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wrEcmv75XF5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to parse ground truth annotations in YOLO format\n",
        "def parse_annotation(annotation_path):\n",
        "    \"\"\"Parse a YOLO-style annotation file.\n",
        "\n",
        "    Extract the class IDs and bounding box information.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(annotation_path):\n",
        "        print(f\"Annotation file {annotation_path} not found.\")\n",
        "        return [], []  # Return empty lists if annotation file is missing\n",
        "\n",
        "    with open(annotation_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    labels = []\n",
        "    boxes = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        class_id = int(parts[0])  # Class ID\n",
        "        # YOLO format: class_id, x_center, y_center, width, height\n",
        "        box = [float(x) for x in parts[1:]]  # Bounding box: [x_center, y_center, width, height]\n",
        "        labels.append(class_id)\n",
        "        boxes.append(box)\n",
        "    return labels, boxes\n",
        "\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(\"./runs/detect/train/weights/best.pt\")\n",
        "\n",
        "# Path to the test images and corresponding labels (annotations)\n",
        "test_image_dir = path + \"/test/images/\"\n",
        "test_label_dir = path + \"/test/labels/\"\n",
        "\n",
        "# Get the list of test images\n",
        "test_images = glob.glob(\n",
        "    os.path.join(test_image_dir, \"*.jpg\")\n",
        ")  # Adjust for correct extension if needed\n",
        "\n",
        "# Output directory to save inference results\n",
        "output_dir = \"./inference_results/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Class names\n",
        "class_names = [\n",
        "    \"Aluminium foil\",\n",
        "    \"Bottle cap\",\n",
        "    \"Bottle\",\n",
        "    \"Broken glass\",\n",
        "    \"Can\",\n",
        "    \"Carton\",\n",
        "    \"Cigarette\",\n",
        "    \"Cup\",\n",
        "    \"Lid\",\n",
        "    \"Other litter\",\n",
        "    \"Other plastic\",\n",
        "    \"Paper\",\n",
        "    \"Plastic bag - wrapper\",\n",
        "    \"Plastic container\",\n",
        "    \"Pop tab\",\n",
        "    \"Straw\",\n",
        "    \"Styrofoam piece\",\n",
        "    \"Unlabeled litter\",\n",
        "]\n",
        "\n",
        "# Loop through each image and perform inference\n",
        "for img_path in test_images:\n",
        "    # Get the corresponding annotation file (in YOLO format)\n",
        "    annotation_path = os.path.join(\n",
        "        test_label_dir, os.path.basename(img_path).replace(\".jpg\", \".txt\").replace(\".JPG\", \".txt\")\n",
        "    )\n",
        "\n",
        "    # Perform inference without verbose output\n",
        "    results = model(img_path, verbose=False)  # Run YOLOv8 on the image\n",
        "\n",
        "    # Get actual labels (ground truth) from annotation file\n",
        "    actual_labels, actual_boxes = parse_annotation(annotation_path)\n",
        "    actual_labels_names = [class_names[label] for label in actual_labels]\n",
        "\n",
        "    # Save the result image with predictions\n",
        "    img_name = os.path.basename(img_path)\n",
        "    result_img_path = os.path.join(output_dir, img_name)\n",
        "    results[0].save(result_img_path)\n",
        "\n",
        "    # Extract predicted labels and bounding boxes\n",
        "    if results[0].boxes is None or len(results[0].boxes.cls) == 0:\n",
        "        predicted_labels = [\"No prediction\"]\n",
        "        predicted_boxes = []\n",
        "    else:\n",
        "        predicted_labels = [results[0].names[int(cls)] for cls in results[0].boxes.cls]\n",
        "        predicted_boxes = (\n",
        "            results[0].boxes.xywh.cpu().numpy()\n",
        "        )  # Ensure numpy format for further processing\n",
        "\n",
        "    # Open the original image for proper ground truth visualization\n",
        "    img_predicted = Image.open(result_img_path)\n",
        "    img_actual = Image.open(img_path)  # Reload the original image for ground truth\n",
        "\n",
        "    # Create drawing objects\n",
        "    draw_predicted = ImageDraw.Draw(img_predicted)\n",
        "    draw_actual = ImageDraw.Draw(img_actual)\n",
        "\n",
        "    # Draw predicted bounding boxes (blue) on the predicted image\n",
        "    img_width, img_height = img_predicted.size\n",
        "    if len(predicted_boxes) == 0:  # Check if predicted_boxes is empty\n",
        "        draw_predicted.text((10, 10), \"No prediction\", fill=\"red\")\n",
        "    else:\n",
        "        for i, box in enumerate(predicted_boxes):\n",
        "            x_center, y_center, width, height = box\n",
        "            x1 = int((x_center - width / 2) * img_width)\n",
        "            y1 = int((y_center - height / 2) * img_height)\n",
        "            x2 = int((x_center + width / 2) * img_width)\n",
        "            y2 = int((y_center + height / 2) * img_height)\n",
        "            draw_predicted.rectangle([x1, y1, x2, y2], outline=\"blue\", width=2)\n",
        "            draw_predicted.text(\n",
        "                (x1, y1),\n",
        "                predicted_labels[i] if i < len(predicted_labels) else \"Unknown\",\n",
        "                fill=\"blue\",\n",
        "            )\n",
        "\n",
        "    # Draw ground truth bounding boxes (green) on the actual image\n",
        "    for i, box in enumerate(actual_boxes):\n",
        "        x_center, y_center, width, height = box\n",
        "        x1 = int((x_center - width / 2) * img_width)\n",
        "        y1 = int((y_center - height / 2) * img_height)\n",
        "        x2 = int((x_center + width / 2) * img_width)\n",
        "        y2 = int((y_center + height / 2) * img_height)\n",
        "        draw_actual.rectangle([x1, y1, x2, y2], outline=\"green\", width=2)\n",
        "        draw_actual.text((x1, y1), actual_labels_names[i], fill=\"white\")\n",
        "\n",
        "    # Display images side by side\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
        "\n",
        "    axes[0].imshow(img_predicted)\n",
        "    axes[0].set_title(\"\\n\".join(predicted_labels), fontsize=14, wrap=True)\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(img_actual)\n",
        "    axes[1].set_title(\"\\n\".join(actual_labels_names), fontsize=14, wrap=True)\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3315500,
          "sourceId": 5768957,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "ml-courses",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
