{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "computer-vision-taken",
            "metadata": {},
            "source": [
                "# Computer Vision Taken\n",
                "\n",
                "Computer vision omvat een breed scala aan taken die elk specifieke uitdagingen en toepassingen hebben. In dit notebook verkennen we de belangrijkste taken en tonen we hoe verschillende architecturen ingezet worden voor deze problemen.\n",
                "\n",
                "## Image Classification\n",
                "\n",
                "**Image classification** is de fundamentele taak van computer vision - het toekennen van een label aan een gehele afbeelding:\n",
                "\n",
                "### Binaire Classificatie\n",
                "\n",
                "```python\n",
                "# Binaire classificatie voorbeeld\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torchvision.transforms as transforms\n",
                "from torchvision.datasets import CIFAR10\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "# Model voor binaire classificatie (kat vs hond)\n",
                "class BinaryClassifier(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(BinaryClassifier, self).__init__()\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2)\n",
                "        )\n",
                "        self.classifier = nn.Sequential(\n",
                "            nn.Dropout(0.5),\n",
                "            nn.Linear(128 * 8 * 8, 512),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.5),\n",
                "            nn.Linear(512, 1),  # Binaire output\n",
                "            nn.Sigmoid()\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = self.features(x)\n",
                "        x = x.view(x.size(0), -1)\n",
                "        x = self.classifier(x)\n",
                "        return x\n",
                "```\n",
                "\n",
                "### Multi-class Classificatie\n",
                "\n",
                "Voor meer dan twee klassen gebruiken we **softmax activatie**:\n",
                "\n",
                "$$\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$$\n",
                "\n",
                "## Object Detection\n",
                "\n",
                "**Object detection** lokaliseert en classificeert objecten in een afbeelding:\n",
                "\n",
                "### Bounding Box Regressie\n",
                "\n",
                "Objecten worden vertegenwoordigd door **bounding boxes** met coordinaten:\n",
                "\n",
                "- **(x, y)**: Centrum van de bounding box\n",
                "- **w, h**: Breedte en hoogte\n",
                "- **c**: Confidence score\n",
                "- **class**: Klasse label\n",
                "\n",
                "### Two-Stage Detectors\n",
                "\n",
                "**Faster R-CNN** gebruikt een twee-staps benadering:\n",
                "\n",
                "1. **Region Proposal Network (RPN)**: Genereert kandidaat regio's\n",
                "2. **Classification**: Klasseert en verfijnt de regio's\n",
                "\n",
                "### One-Stage Detectors\n",
                "\n",
                "**YOLO (You Only Look Once)** behandelt detection als een regressie probleem:\n",
                "\n",
                "```python\n",
                "# YOLO output voor elke grid cell\n",
                "output = [\n",
                "    p_c,                    # Object confidence\n",
                "    x, y, w, h,            # Bounding box coordinaten\n",
                "    p_class1, p_class2,    # Klasse probabilities\n",
                "    ...\n",
                "]\n",
                "```\n",
                "\n",
                "## Semantic Segmentation\n",
                "\n",
                "**Semantic segmentation** classificeert elke pixel in de afbeelding:\n",
                "\n",
                "### Fully Convolutional Networks\n",
                "\n",
                "FCNs vervangen fully connected lagen door **convolutionele lagen**:\n",
                "\n",
                "```python\n",
                "# FCN voor semantic segmentation\n",
                "class FCN(nn.Module):\n",
                "    def __init__(self, num_classes):\n",
                "        super(FCN, self).__init__()\n",
                "        \n",
                "        # Encoder (downsampling)\n",
                "        self.encoder = nn.Sequential(\n",
                "            nn.Conv2d(3, 64, 3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(64, 64, 3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            # ... meer lagen\n",
                "        )\n",
                "        \n",
                "        # Decoder (upsampling)\n",
                "        self.decoder = nn.Sequential(\n",
                "            nn.ConvTranspose2d(512, 256, 2, stride=2),\n",
                "            nn.ReLU(),\n",
                "            nn.ConvTranspose2d(256, num_classes, 2, stride=2),\n",
                "        )\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x = self.encoder(x)\n",
                "        x = self.decoder(x)\n",
                "        return x\n",
                "```\n",
                "\n",
                "### U-Net Architectuur\n",
                "\n",
                "**U-Net** gebruikt skip connections tussen encoder en decoder:\n",
                "\n",
                "- **Contracting path**: Feature extractie\n",
                "- **Expansive path**: Lokalisatie met skip connections\n",
                "- **Final layer**: Pixel-wise classificatie\n",
                "\n",
                "## Instance Segmentation\n",
                "\n",
                "**Instance segmentation** combineert object detection met semantic segmentation:\n",
                "\n",
                "### Mask R-CNN\n",
                "\n",
                "Mask R-CNN voegt een **mask prediction branch** toe aan Faster R-CNN:\n",
                "\n",
                "1. **Backbone**: Feature extractie (ResNet, etc.)\n",
                "2. **RPN**: Region proposals\n",
                "3. **Box head**: Bounding box regressie en classificatie\n",
                "4. **Mask head**: Binary mask voor elk gedetecteerd object\n",
                "\n",
                "## Keypoint Detection\n",
                "\n",
                "**Keypoint detection** lokaliseert specifieke punten in objecten:\n",
                "\n",
                "### Human Pose Estimation\n",
                "\n",
                "Voor menselijke pose detecteren we **17 keypoints**:\n",
                "\n",
                "- Neus, ogen, oren\n",
                "- Schouders, ellebogen, polsen\n",
                "- Heupen, knieÃ«n, enkels\n",
                "\n",
                "### Heatmap Regressie\n",
                "\n",
                "Keypoints worden voorspeld als **heatmaps**:\n",
                "\n",
                "```python\n",
                "# Voor 17 keypoints op 56x56 grid\n",
                "heatmap = model(image)  # Shape: (batch, 17, 56, 56)\n",
                "keypoints = argmax_2d(heatmap)  # Extract (x, y) coordinaten\n",
                "```\n",
                "\n",
                "## Optical Character Recognition (OCR)\n",
                "\n",
                "**OCR** combineert tekst detectie met tekst herkenning:\n",
                "\n",
                "### Text Detection\n",
                "\n",
                "Verschillende benaderingen:\n",
                "- **Regression-based**: Voorspel bounding boxes voor tekstregio's\n",
                "- **Segmentation-based**: Classificeer pixels als tekst/niet-tekst\n",
                "- **Component-based**: Groepeer connected components\n",
                "\n",
                "### Text Recognition\n",
                "\n",
                "Text recognition gebruikt vaak **sequence modeling**:\n",
                "\n",
                "```python\n",
                "# CRNN: CNN + RNN voor tekstherkenning\n",
                "class CRNN(nn.Module):\n",
                "    def __init__(self, num_classes):\n",
                "        super(CRNN, self).__init__()\n",
                "        \n",
                "        # Feature extraction\n",
                "        self.cnn = nn.Sequential(\n",
                "            nn.Conv2d(1, 64, 3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            # ... meer CNN lagen\n",
                "        )\n",
                "        \n",
                "        # Sequence modeling\n",
                "        self.rnn = nn.LSTM(512, 256, bidirectional=True)\n",
                "        \n",
                "        # Transcription\n",
                "        self.fc = nn.Linear(512, num_classes)\n",
                "```\n",
                "\n",
                "## Representation Learning\n",
                "\n",
                "**Representation learning** leert algemene visuele representaties:\n",
                "\n",
                "### Self-Supervised Learning\n",
                "\n",
                "Leren zonder menselijke labels:\n",
                "\n",
                "- **Contrastive Learning**: Vergelijk positieve en negatieve paren\n",
                "- **Masked Image Modeling**: Voorspel gemaskeerde beeldregio's\n",
                "- **Rotation Prediction**: Voorspel rotatiehoek van afbeelding\n",
                "\n",
                "### Contrastive Learning Framework\n",
                "\n",
                "```python\n",
                "# SimCLR: Simple Contrastive Learning\n",
                "def contrastive_loss(representations, temperature=0.5):\n",
                "    \"\"\"\n",
                "    NT-Xent loss voor contrastive learning\n",
                "    \"\"\"\n",
                "    batch_size = representations.size(0)\n",
                "    \n",
                "    # Normaliseer representaties\n",
                "    representations = F.normalize(representations, dim=1)\n",
                "    \n",
                "    # Similarity matrix\n",
                "    similarity_matrix = torch.matmul(representations, representations.T)\n",
                "    \n",
                "    # Mask voor positieve paren\n",
                "    mask = torch.eye(batch_size, dtype=torch.bool)\n",
                "    \n",
                "    # Loss berekening\n",
                "    positives = similarity_matrix[mask].view(batch_size, -1)\n",
                "    negatives = similarity_matrix[~mask].view(batch_size, -1)\n",
                "    \n",
                "    logits = torch.cat([positives, negatives], dim=1)\n",
                "    labels = torch.zeros(batch_size, dtype=torch.long)\n",
                "    \n",
                "    return F.cross_entropy(logits / temperature, labels)\n",
                "```\n",
                "\n",
                "## Taak-Specifieke Uitdagingen\n",
                "\n",
                "### Class Imbalance\n",
                "\n",
                "In object detection: achtergrond vs objecten\n",
                "\n",
                "### Scale Variation\n",
                "\n",
                "Objecten kunnen sterk verschillen in grootte\n",
                "\n",
                "### Occlusion\n",
                "\n",
                "Gedeeltelijk zichtbare objecten\n",
                "\n",
                "### Multi-label Classification\n",
                "\n",
                "Afbeeldingen kunnen meerdere labels hebben"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "taken-vergelijking",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Verschillende taken vergelijken\n",
                "def compare_vision_tasks():\n",
                "    \"\"\"Vergelijk verschillende computer vision taken\"\"\"\n",
                "    \n",
                "    tasks = {\n",
                "        'Classification': {\n",
                "            'output': 'Single label per image',\n",
                "            'difficulty': 'Low',\n",
                "            'applications': ['Image search', 'Content filtering'],\n",
                "            'metrics': ['Accuracy', 'Precision', 'Recall']\n",
                "        },\n",
                "        'Object Detection': {\n",
                "            'output': 'Bounding boxes + labels',\n",
                "            'difficulty': 'Medium',\n",
                "            'applications': ['Autonomous driving', 'Surveillance'],\n",
                "            'metrics': ['mAP', 'IoU', 'Precision']\n",
                "        },\n",
                "        'Semantic Segmentation': {\n",
                "            'output': 'Pixel-wise labels',\n",
                "            'difficulty': 'High',\n",
                "            'applications': ['Medical imaging', 'Autonomous driving'],\n",
                "            'metrics': ['mIoU', 'Pixel accuracy']\n",
                "        },\n",
                "        'Instance Segmentation': {\n",
                "            'output': 'Instance masks + labels',\n",
                "            'difficulty': 'Very High',\n",
                "            'applications': ['Medical analysis', 'Robotics'],\n",
                "            'metrics': ['mAP', 'Mask IoU']\n",
                "        }\n",
                "    }\n",
                "    \n",
                "    # Visualisatie\n",
                "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
                "    \n",
                "    # Difficulty comparison\n",
                "    task_names = list(tasks.keys())\n",
                "    difficulties = ['Low', 'Medium', 'High', 'Very High']\n",
                "    diff_values = [difficulties.index(tasks[task]['difficulty']) for task in task_names]\n",
                "    \n",
                "    bars = ax1.bar(range(len(task_names)), diff_values, alpha=0.7)\n",
                "    ax1.set_xlabel('Task')\n",
                "    ax1.set_ylabel('Difficulty Level')\n",
                "    ax1.set_title('Computer Vision Tasks: Difficulty Comparison')\n",
                "    ax1.set_xticks(range(len(task_names)))\n",
                "    ax1.set_xticklabels(task_names, rotation=45)\n",
                "    ax1.set_yticks(range(len(difficulties)))\n",
                "    ax1.set_yticklabels(difficulties)\n",
                "    \n",
                "    # Voeg output informatie toe\n",
                "    for i, bar in enumerate(bars):\n",
                "        height = bar.get_height()\n",
                "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
                "                tasks[task_names[i]]['output'],\n",
                "                ha='center', va='bottom', rotation=45, fontsize=8)\n",
                "    \n",
                "    # Applications word cloud style\n",
                "    ax2.axis('off')\n",
                "    ax2.set_title('Applications by Task')\n",
                "    \n",
                "    y_pos = 0.8\n",
                "    for task, info in tasks.items():\n",
                "        ax2.text(0.1, y_pos, f\"{task}:\", fontweight='bold')\n",
                "        for app in info['applications']:\n",
                "            y_pos -= 0.1\n",
                "            ax2.text(0.2, y_pos, f\"â¢ {app}\")\n",
                "        y_pos -= 0.1\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    return tasks\n",
                "\n",
                "# Vergelijk taken\n",
                "tasks = compare_vision_tasks()\n",
                "\n",
                "print(\"\\nGedetailleerde Task Vergelijking:\")\n",
                "for task, info in tasks.items():\n",
                "    print(f\"\\n{task}:\")\n",
                "    print(f\"  Output: {info['output']}\")\n",
                "    print(f\"  Difficulty: {info['difficulty']}\")\n",
                "    print(f\"  Applications: {', '.join(info['applications'])}\")\n",
                "    print(f\"  Metrics: {', '.join(info['metrics'])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "praktische-voorbeelden",
            "metadata": {},
            "source": [
                "## Praktische Voorbeelden per Taak\n",
                "\n",
                "Laten we kijken naar concrete implementaties voor verschillende taken:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "voorbeeld-implementaties",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Voorbeeld implementaties voor verschillende taken\n",
                "\n",
                "# 1. Image Classification Model\n",
                "class ImageClassifier(nn.Module):\n",
                "    \"\"\"Model voor image classification\"\"\"\n",
                "    def __init__(self, num_classes=10):\n",
                "        super(ImageClassifier, self).__init__()\n",
                "        self.conv_layers = nn.Sequential(\n",
                "            nn.Conv2d(3, 32, 3, padding=1),\n",
                "            nn.BatchNorm2d(32),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            nn.Conv2d(32, 64, 3, padding=1),\n",
                "            nn.BatchNorm2d(64),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            nn.Conv2d(64, 128, 3, padding=1),\n",
                "            nn.BatchNorm2d(128),\n",
                "            nn.ReLU(),\n",
                "            nn.AdaptiveAvgPool2d(1)\n",
                "        )\n",
                "        self.classifier = nn.Linear(128, num_classes)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = self.conv_layers(x)\n",
                "        x = x.view(x.size(0), -1)\n",
                "        x = self.classifier(x)\n",
                "        return x\n",
                "\n",
                "# 2. Simple Object Detector (conceptueel)\n",
                "class SimpleObjectDetector(nn.Module):\n",
                "    \"\"\"Conceptueel model voor object detection\"\"\"\n",
                "    def __init__(self, num_classes=20, num_boxes=2, grid_size=7):\n",
                "        super(SimpleObjectDetector, self).__init__()\n",
                "        self.grid_size = grid_size\n",
                "        \n",
                "        # Feature extractor\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv2d(3, 64, 3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            # ... meer lagen\n",
                "        )\n",
                "        \n",
                "        # Detection head: voor elke grid cell voorspel\n",
                "        # [p_c, x, y, w, h, p_class1, p_class2, ...]\n",
                "        output_channels = num_boxes * (5 + num_classes)  # 5 = p_c, x, y, w, h\n",
                "        self.detector = nn.Conv2d(64, output_channels, 1)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = self.features(x)\n",
                "        x = self.detector(x)\n",
                "        # Reshape naar (batch, grid, grid, num_boxes * (5 + num_classes))\n",
                "        x = x.permute(0, 2, 3, 1)\n",
                "        return x\n",
                "\n",
                "# 3. Simple Segmentation Model\n",
                "class SimpleSegmentationModel(nn.Module):\n",
                "    \"\"\"Model voor semantic segmentation\"\"\"\n",
                "    def __init__(self, num_classes=21):\n",
                "        super(SimpleSegmentationModel, self).__init__()\n",
                "        \n",
                "        # Encoder\n",
                "        self.encoder = nn.Sequential(\n",
                "            nn.Conv2d(3, 64, 3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(64, 64, 3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2)\n",
                "        )\n",
                "        \n",
                "        # Decoder\n",
                "        self.decoder = nn.Sequential(\n",
                "            nn.ConvTranspose2d(64, 64, 2, stride=2),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(64, num_classes, 1)\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = self.encoder(x)\n",
                "        x = self.decoder(x)\n",
                "        return x\n",
                "\n",
                "# Model vergelijking\n",
                "models = {\n",
                "    'Classification': ImageClassifier(),\n",
                "    'Object Detection': SimpleObjectDetector(),\n",
                "    'Segmentation': SimpleSegmentationModel()\n",
                "}\n",
                "\n",
                "print(\"Model Output Shapes Vergelijking:\")\n",
                "dummy_input = torch.randn(1, 3, 224, 224)\n",
                "\n",
                "for name, model in models.items():\n",
                "    with torch.no_grad():\n",
                "        output = model(dummy_input)\n",
                "    print(f\"{name}: {output.shape}\")\n",
                "    \n",
                "    # Bereken aantal parameters\n",
                "    total_params = sum(p.numel() for p in model.parameters())\n",
                "    print(f\"  Parameters: {total_params:,}\")\n",
                "    print()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}