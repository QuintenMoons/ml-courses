{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "convolutional-neural-networks",
            "metadata": {},
            "source": [
                "# Convolutional Neural Networks (CNNs)\n",
                "\n",
                "**Convolutional Neural Networks** vormen de ruggengraat van moderne computer vision. Ze zijn specifiek ontworpen om efficiënt om te gaan met de grid-achtige structuur van beeldgegevens en kunnen hiërarchische patronen leren van lokale beeldregio's.\n",
                "\n",
                "## Model Architectuur\n",
                "\n",
                "CNNs bestaan typisch uit verschillende lagen die elk een specifieke functie vervullen:\n",
                "\n",
                "### Convolutionele Lagen\n",
                "\n",
                "De **kerncomponent** van CNNs zijn de convolutionele lagen die **filters** (kernels) gebruiken om lokale patronen te detecteren:\n",
                "\n",
                "```python\n",
                "# Illustratie van een convolutionele operatie\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "# Convolutionele laag: 3 input kanalen, 64 output filters, 3x3 kernel\n",
                "conv_layer = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
                "```\n",
                "\n",
                "### Activatie Functies\n",
                "\n",
                "**ReLU (Rectified Linear Unit)** is de meest gebruikte activatie functie:\n",
                "\n",
                "$$f(x) = \\max(0, x)$$\n",
                "\n",
                "### Pooling Lagen\n",
                "\n",
                "**Max pooling** reduceert de spatial dimensies terwijl belangrijke informatie behouden blijft:\n",
                "\n",
                "```python\n",
                "# Max pooling laag\n",
                "pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
                "```\n",
                "\n",
                "### Fully Connected Lagen\n",
                "\n",
                "Aan het einde van het netwerk vertalen **dense lagen** de geleerde features naar de gewenste output.\n",
                "\n",
                "## Parameters\n",
                "\n",
                "CNN parameters bestaan uit:\n",
                "\n",
                "- **Filter weights**: De convolutionele kernels\n",
                "- **Biases**: Offset termen voor elke output feature map\n",
                "- **Batch normalization parameters**: Schaal- en verschuivingsparameters\n",
                "- **Dense layer weights**: Gewichten voor de classificatie lagen\n",
                "\n",
                "### Parameter Delen\n",
                "\n",
                "Een cruciaal aspect van CNNs is **parameter sharing** - dezelfde filters worden gebruikt over de gehele beeld:\n",
                "\n",
                "```python\n",
                "# Voor een 3x3 filter zijn er 3×3×3 = 27 parameters per filter\n",
                "# Deze worden gedeeld over alle posities in de afbeelding\n",
                "shared_params = 27  # per filter\n",
                "```\n",
                "\n",
                "## Features\n",
                "\n",
                "CNNs extraheren automatisch hiërarchische features:\n",
                "\n",
                "### Lage Niveaus\n",
                "- **Edges en texturen**\n",
                "- **Eenvoudige patronen**\n",
                "- **Kleurcontrasten**\n",
                "\n",
                "### Hoge Niveaus\n",
                "- **Objectonderdelen**\n",
                "- **Complexe structuren**\n",
                "- **Semantische concepten**\n",
                "\n",
                "### Translation Invariantie\n",
                "\n",
                "CNNs zijn van nature **translation invariant** - ze herkennen patronen ongeacht hun positie in het beeld.\n",
                "\n",
                "## Optimalisatie\n",
                "\n",
                "### Backpropagation in CNNs\n",
                "\n",
                "Het leerproces gebruikt **gradient descent** om de filters te optimaliseren:\n",
                "\n",
                "```python\n",
                "# Training loop\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    optimizer.zero_grad()\n",
                "    outputs = model(inputs)\n",
                "    loss = criterion(outputs, labels)\n",
                "    loss.backward()  # Backpropagation\n",
                "    optimizer.step()\n",
                "```\n",
                "\n",
                "### Gradient Flow\n",
                "\n",
                "De gradienten stromen terug door het netwerk om alle parameters bij te werken.\n",
                "\n",
                "## Taken en Ervaring\n",
                "\n",
                "CNNs worden gebruikt voor **supervised learning** taken:\n",
                "\n",
                "- **Image classification**\n",
                "- **Object detection**\n",
                "- **Semantic segmentation**\n",
                "\n",
                "### Data Annotatie\n",
                "\n",
                "Training vereist **grote hoeveelheden gelabelde data**:\n",
                "- Handmatige annotatie door experts\n",
                "- Crowd-sourcing platforms\n",
                "- Automatische labeling technieken\n",
                "\n",
                "## Performantie\n",
                "\n",
                "### Evaluatie Metrieken\n",
                "\n",
                "- **Accuracy**: Percentage correcte voorspellingen\n",
                "- **Precision & Recall**: Balans tussen false positives en false negatives\n",
                "- **F1-score**: Harmonisch gemiddelde van precision en recall\n",
                "\n",
                "### Computationele Kost\n",
                "\n",
                "CNNs vereisen:\n",
                "- **GPU acceleratie** voor training\n",
                "- **Grote hoeveelheden geheugen**\n",
                "- **Parallelle berekening** voor efficiëntie\n",
                "\n",
                "## Voordelen\n",
                "\n",
                "- **Automatische feature extractie**\n",
                "- **Translation invariantie**\n",
                "- **Hiërarchische representatie learning**\n",
                "- **End-to-end training**\n",
                "- **Herbruikbaarheid via transfer learning**\n",
                "\n",
                "## Nadelen\n",
                "\n",
                "- **Grote hoeveelheden trainingsdata nodig**\n",
                "- **Computationeel intensief**\n",
                "- **Moeilijk te interpreteren** (black box)\n",
                "- **Gevoelig voor adversarial examples**\n",
                "- **Overfitting bij kleine datasets**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cnn-illustratie",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Eenvoudige CNN voor MNIST cijfers\n",
                "class SimpleCNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(SimpleCNN, self).__init__()\n",
                "        \n",
                "        # Convolutionele lagen\n",
                "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
                "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
                "        \n",
                "        # Pooling lagen\n",
                "        self.pool = nn.MaxPool2d(2, 2)\n",
                "        \n",
                "        # Fully connected lagen\n",
                "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
                "        self.fc2 = nn.Linear(128, 10)\n",
                "        \n",
                "        # Dropout voor regularisatie\n",
                "        self.dropout = nn.Dropout(0.5)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # Convolution + ReLU + Pooling\n",
                "        x = self.pool(F.relu(self.conv1(x)))\n",
                "        x = self.pool(F.relu(self.conv2(x)))\n",
                "        \n",
                "        # Flatten voor dense lagen\n",
                "        x = x.view(-1, 64 * 7 * 7)\n",
                "        \n",
                "        # Dense lagen met dropout\n",
                "        x = F.relu(self.fc1(x))\n",
                "        x = self.dropout(x)\n",
                "        x = self.fc2(x)\n",
                "        \n",
                "        return x\n",
                "\n",
                "# Model initialisatie\n",
                "model = SimpleCNN()\n",
                "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
                "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
                "\n",
                "# Visualisatie van de model architectuur\n",
                "print(\"\\nModel Architectuur:\")\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feature-maps",
            "metadata": {},
            "source": [
                "## Feature Map Visualisatie\n",
                "\n",
                "Laten we kijken hoe de feature maps evolueren door de CNN lagen:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feature-visualisatie",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torchvision\n",
                "from torchvision import transforms\n",
                "\n",
                "# Laad een voorbeeld afbeelding (MNIST stijl)\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5,), (0.5,))\n",
                "])\n",
                "\n",
                "# Maak een dummy afbeelding voor illustratie\n",
                "dummy_input = torch.randn(1, 1, 28, 28)\n",
                "\n",
                "# Visualisatie functie\n",
                "def visualize_feature_maps(model, input_tensor, layer_name):\n",
                "    \"\"\"Visualiseer feature maps voor een specifieke laag\"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    # Hook om feature maps te capturen\n",
                "    feature_maps = []\n",
                "    def hook_fn(module, input, output):\n",
                "        feature_maps.append(output.detach())\n",
                "    \n",
                "    # Registreer hook op de gewenste laag\n",
                "    if layer_name == 'conv1':\n",
                "        model.conv1.register_forward_hook(hook_fn)\n",
                "    elif layer_name == 'conv2':\n",
                "        model.conv2.register_forward_hook(hook_fn)\n",
                "    \n",
                "    # Forward pass\n",
                "    with torch.no_grad():\n",
                "        output = model(input_tensor)\n",
                "    \n",
                "    return feature_maps[0] if feature_maps else None\n",
                "\n",
                "# Genereer feature maps\n",
                "conv1_features = visualize_feature_maps(model, dummy_input, 'conv1')\n",
                "conv2_features = visualize_feature_maps(model, dummy_input, 'conv2')\n",
                "\n",
                "print(f\"Conv1 feature maps shape: {conv1_features.shape}\")\n",
                "print(f\"Conv2 feature maps shape: {conv2_features.shape}\")\n",
                "\n",
                "# Plot eerste paar feature maps\n",
                "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
                "\n",
                "for i in range(4):\n",
                "    # Conv1 feature maps\n",
                "    axes[0, i].imshow(conv1_features[0, i].cpu().numpy(), cmap='viridis')\n",
                "    axes[0, i].set_title(f'Conv1 - Filter {i+1}')\n",
                "    axes[0, i].axis('off')\n",
                "    \n",
                "    # Conv2 feature maps\n",
                "    axes[1, i].imshow(conv2_features[0, i].cpu().numpy(), cmap='viridis')\n",
                "    axes[1, i].set_title(f'Conv2 - Filter {i+1}')\n",
                "    axes[1, i].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}